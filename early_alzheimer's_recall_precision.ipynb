{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1\n",
    "import math\n",
    "import csv\n",
    "from numpy import genfromtxt\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "from tf_utils import load_dataset, random_mini_batches, convert_to_one_hot, predict\n",
    "\n",
    "%matplotlib inline\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training examples = 248\n",
      "number of test examples = 106\n",
      "X_train shape: (10, 248)\n",
      "Y_train shape: (3, 248)\n",
      "X_test shape: (10, 106)\n",
      "Y_test shape: (3, 106)\n"
     ]
    }
   ],
   "source": [
    "# 16, 17, 18\n",
    "XY_orig=genfromtxt('oasis_longitudinal_edited_csv.csv', delimiter=',')\n",
    "XY_orig=np.matrix(XY_orig)          #original excel dataset\n",
    "X_orig=XY_orig[1:355, 4:14].T       #eliminate feature-names, labels, unnecessary features and transpose to get X_orig\n",
    "Y_orig=XY_orig[1:355, 14].T         #extract labels and transpose to get Y\n",
    "X_orig_max = X_orig.max(1)          #normalizing features\n",
    "X_orig=X_orig/X_orig_max\n",
    "\n",
    "X_train=X_orig[:, 0:248]            #split into X_train\n",
    "Y_train=Y_orig[:, 0:248]            #split into Y_train\n",
    "\n",
    "X_test=X_orig[:, 248:354]           #split into X_test\n",
    "Y_test=Y_orig[:, 248:354]           #split into Y_test\n",
    "\n",
    "X_train=np.array(X_train)           #convert to array from matrices\n",
    "X_test=np.array(X_test)\n",
    "Y_train=np.array(Y_train)\n",
    "Y_test=np.array(Y_test)\n",
    "\n",
    "Y_train=Y_train.astype(int)         #convert to one-hot\n",
    "Y_test=Y_test.astype(int)\n",
    "Y_train=convert_to_one_hot(Y_train, 3)\n",
    "Y_test=convert_to_one_hot(Y_test, 3)\n",
    "\n",
    "print (\"number of training examples = \" + str(X_train.shape[1]))      #print out dimensions\n",
    "print (\"number of test examples = \" + str(X_test.shape[1]))\n",
    "print (\"X_train shape: \" + str(X_train.shape))\n",
    "print (\"Y_train shape: \" + str(Y_train.shape))\n",
    "print (\"X_test shape: \" + str(X_test.shape))\n",
    "print (\"Y_test shape: \" + str(Y_test.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 19\n",
    "def create_placeholders(n_x, n_y):\n",
    "    \"\"\"\n",
    "    Creates the placeholders for the tensorflow session.\n",
    "    \n",
    "    Arguments:\n",
    "    n_x -- scalar, size of an image vector (num_px * num_px = 64 * 64 * 3 = 12288)\n",
    "    n_y -- scalar, number of classes (from 0 to 5, so -> 6)\n",
    "    \n",
    "    Returns:\n",
    "    X -- placeholder for the data input, of shape [n_x, None] and dtype \"float\"\n",
    "    Y -- placeholder for the input labels, of shape [n_y, None] and dtype \"float\"\n",
    "    \n",
    "    Tips:\n",
    "    - You will use None because it let's us be flexible on the number of examples you will for the placeholders.\n",
    "      In fact, the number of examples during test/train is different.\n",
    "    \"\"\"\n",
    "\n",
    "    ### START CODE HERE ### (approx. 2 lines)\n",
    "    X = tf.placeholder(tf.float32, [n_x, None])\n",
    "    Y = tf.placeholder(tf.float32, [n_y, None])\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 21\n",
    "def initialize_parameters():\n",
    "    \"\"\"\n",
    "    Initializes parameters to build a neural network with tensorflow. The shapes are:\n",
    "                        W1 : [10, 10]\n",
    "                        b1 : [10, 1]\n",
    "                        W2 : [10, 10]\n",
    "                        b2 : [10, 1]\n",
    "                        W3 : [3, 10]\n",
    "                        b3 : [3, 1]\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- a dictionary of tensors containing W1, b1, W2, b2, W3, b3\n",
    "    \"\"\"\n",
    "    \n",
    "    tf.set_random_seed(1)                   # so that your \"random\" numbers match ours\n",
    "        \n",
    "    ### START CODE HERE ### (approx. 6 lines of code)\n",
    "    W1 = tf.get_variable(\"W1\", [10, 10], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b1 = tf.get_variable(\"b1\", [10, 1], initializer = tf.zeros_initializer())\n",
    "    W2 = tf.get_variable(\"W2\", [10, 10], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b2 = tf.get_variable(\"b2\", [10, 1], initializer = tf.zeros_initializer())\n",
    "    W3 = tf.get_variable(\"W3\", [3, 10], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b3 = tf.get_variable(\"b3\", [3, 1], initializer = tf.zeros_initializer())\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"b1\": b1,\n",
    "                  \"W2\": W2,\n",
    "                  \"b2\": b2,\n",
    "                  \"W3\": W3,\n",
    "                  \"b3\": b3}\n",
    "    \n",
    "    return parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 23\n",
    "def forward_propagation(X, parameters):\n",
    "    \"\"\"\n",
    "    Implements the forward propagation for the model: LINEAR -> RELU -> LINEAR -> RELU -> LINEAR -> SOFTMAX\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input dataset placeholder, of shape (input size, number of examples)\n",
    "    parameters -- python dictionary containing your parameters \"W1\", \"b1\", \"W2\", \"b2\", \"W3\", \"b3\"\n",
    "                  the shapes are given in initialize_parameters\n",
    "\n",
    "    Returns:\n",
    "    Z3 -- the output of the last LINEAR unit\n",
    "    \"\"\"\n",
    "    \n",
    "    # Retrieve the parameters from the dictionary \"parameters\" \n",
    "    W1 = parameters['W1']\n",
    "    b1 = parameters['b1']\n",
    "    W2 = parameters['W2']\n",
    "    b2 = parameters['b2']\n",
    "    W3 = parameters['W3']\n",
    "    b3 = parameters['b3']\n",
    "    \n",
    "    ### START CODE HERE ### (approx. 5 lines)                                      # Numpy Equivalents:\n",
    "    Z1 = tf.add(tf.matmul(W1, X), b1)                                              # Z1 = np.dot(W1, X) + b1\n",
    "    A1 = tf.nn.relu(Z1)                                                            # A1 = relu(Z1)\n",
    "    Z2 = tf.add(tf.matmul(W2, A1), b2)                                             # Z2 = np.dot(W2, a1) + b2\n",
    "    A2 = tf.nn.relu(Z2)                                                            # A2 = relu(Z2)\n",
    "    Z3 = tf.add(tf.matmul(W3, A2), b3)                                             # Z3 = np.dot(W3,Z2) + b3\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return Z3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 25\n",
    "def compute_cost(Z3, Y):\n",
    "    \"\"\"\n",
    "    Computes the cost\n",
    "    \n",
    "    Arguments:\n",
    "    Z3 -- output of forward propagation (output of the last LINEAR unit), of shape (6, number of examples)\n",
    "    Y -- \"true\" labels vector placeholder, same shape as Z3\n",
    "    \n",
    "    Returns:\n",
    "    cost - Tensor of the cost function\n",
    "    \"\"\"\n",
    "    \n",
    "    # to fit the tensorflow requirement for tf.nn.softmax_cross_entropy_with_logits(...,...)\n",
    "    logits = tf.transpose(Z3)\n",
    "    labels = tf.transpose(Y)\n",
    "    \n",
    "    ### START CODE HERE ### (1 line of code)\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=labels))\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 27\n",
    "def model(X_train, Y_train, X_test, Y_test, learning_rate = 0.0001,\n",
    "          num_epochs = 1500, minibatch_size = 32, print_cost = True):\n",
    "    \"\"\"\n",
    "    Implements a three-layer tensorflow neural network: LINEAR->RELU->LINEAR->RELU->LINEAR->SOFTMAX.\n",
    "    \n",
    "    Arguments:\n",
    "    X_train -- training set, of shape (input size = 12288, number of training examples = 1080)\n",
    "    Y_train -- test set, of shape (output size = 6, number of training examples = 1080)\n",
    "    X_test -- training set, of shape (input size = 12288, number of training examples = 120)\n",
    "    Y_test -- test set, of shape (output size = 6, number of test examples = 120)\n",
    "    learning_rate -- learning rate of the optimization\n",
    "    num_epochs -- number of epochs of the optimization loop\n",
    "    minibatch_size -- size of a minibatch\n",
    "    print_cost -- True to print the cost every 100 epochs\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- parameters learnt by the model. They can then be used to predict.\n",
    "    \"\"\"\n",
    "    \n",
    "    ops.reset_default_graph()                         # to be able to rerun the model without overwriting tf variables\n",
    "    tf.set_random_seed(1)                             # to keep consistent results\n",
    "    seed = 3                                          # to keep consistent results\n",
    "    (n_x, m) = X_train.shape                          # (n_x: input size, m : number of examples in the train set)\n",
    "    n_y = Y_train.shape[0]                            # n_y : output size\n",
    "    costs = []                                        # To keep track of the cost\n",
    "    \n",
    "    # Create Placeholders of shape (n_x, n_y)\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    X, Y = create_placeholders(n_x, n_y)\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    # Initialize parameters\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    parameters = initialize_parameters()\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Forward propagation: Build the forward propagation in the tensorflow graph\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    Z3 = forward_propagation(X, parameters)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Cost function: Add cost function to tensorflow graph\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    cost = compute_cost(Z3, Y)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Backpropagation: Define the tensorflow optimizer. Use an AdamOptimizer.\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(cost)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Initialize all the variables\n",
    "    init = tf.global_variables_initializer()\n",
    "\n",
    "    # Start the session to compute the tensorflow graph\n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        # Run the initialization\n",
    "        sess.run(init)\n",
    "        \n",
    "        # Do the training loop\n",
    "        for epoch in range(num_epochs):\n",
    "\n",
    "            epoch_cost = 0.                       # Defines a cost related to an epoch\n",
    "            num_minibatches = int(m / minibatch_size) # number of minibatches of size minibatch_size in the train set\n",
    "            seed = seed + 1\n",
    "            minibatches = random_mini_batches(X_train, Y_train, minibatch_size, seed)\n",
    "\n",
    "            for minibatch in minibatches:\n",
    "\n",
    "                # Select a minibatch\n",
    "                (minibatch_X, minibatch_Y) = minibatch\n",
    "                \n",
    "                # IMPORTANT: The line that runs the graph on a minibatch.\n",
    "                # Run the session to execute the \"optimizer\" and the \"cost\", the feedict should contain a minibatch for (X,Y).\n",
    "                ### START CODE HERE ### (1 line)\n",
    "                _ , minibatch_cost = sess.run([optimizer, cost], feed_dict={X: minibatch_X, Y: minibatch_Y})\n",
    "                ### END CODE HERE ###\n",
    "                \n",
    "                epoch_cost += minibatch_cost / num_minibatches\n",
    "\n",
    "            # Print the cost every epoch\n",
    "            if print_cost == True and epoch % 100 == 0:\n",
    "                print (\"Cost after epoch %i: %f\" % (epoch, epoch_cost))\n",
    "            if print_cost == True and epoch % 5 == 0:\n",
    "                costs.append(epoch_cost)\n",
    "                \n",
    "        # plot the cost\n",
    "        plt.plot(np.squeeze(costs))\n",
    "        plt.ylabel('cost')\n",
    "        plt.xlabel('iterations (per tens)')\n",
    "        plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "        plt.show()\n",
    "\n",
    "        # lets save the parameters in a variable\n",
    "        parameters = sess.run(parameters)\n",
    "        print (\"Parameters have been trained!\")\n",
    "        print()\n",
    "\n",
    "        # Calculate accuracies\n",
    "        #Calculate the correct predictions\n",
    "        correct_prediction = tf.equal(tf.argmax(Z3), tf.argmax(Y))\n",
    "        # Calculate accuracy on the test set\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "        print (\"Train Accuracy:\", accuracy.eval({X: X_train, Y: Y_train}))\n",
    "        print (\"Test Accuracy:\", accuracy.eval({X: X_test, Y: Y_test}))\n",
    "        print()\n",
    "        \n",
    "        # Calculating recall for category 0\n",
    "        predicted0_actual0 = tf.reduce_sum(tf.cast(tf.logical_and(tf.equal(tf.argmax(Z3), 0), tf.equal(tf.argmax(Y), 0)), \"float\"))\n",
    "        predicted1_actual0 = tf.reduce_sum(tf.cast(tf.logical_and(tf.equal(tf.argmax(Z3), 1), tf.equal(tf.argmax(Y), 0)), \"float\"))\n",
    "        predicted2_actual0 = tf.reduce_sum(tf.cast(tf.logical_and(tf.equal(tf.argmax(Z3), 2), tf.equal(tf.argmax(Y), 0)), \"float\")) \n",
    "        recall0=tf.divide(predicted0_actual0, tf.add_n([predicted0_actual0, predicted1_actual0, predicted2_actual0]))\n",
    "        print (\"Train Recall for category 0:\", recall0.eval({X: X_train, Y: Y_train}))\n",
    "        print (\"Test Recall for category 0:\", recall0.eval({X: X_test, Y: Y_test}))\n",
    "        print()\n",
    "        \n",
    "        # Calculating recall for category 1\n",
    "        predicted1_actual1 = tf.reduce_sum(tf.cast(tf.logical_and(tf.equal(tf.argmax(Z3), 1), tf.equal(tf.argmax(Y), 1)), \"float\"))\n",
    "        predicted0_actual1 = tf.reduce_sum(tf.cast(tf.logical_and(tf.equal(tf.argmax(Z3), 0), tf.equal(tf.argmax(Y), 1)), \"float\"))\n",
    "        predicted2_actual1 = tf.reduce_sum(tf.cast(tf.logical_and(tf.equal(tf.argmax(Z3), 2), tf.equal(tf.argmax(Y), 1)), \"float\")) \n",
    "        recall1=tf.divide(predicted1_actual1, tf.add_n([predicted1_actual1, predicted0_actual1, predicted2_actual1]))\n",
    "        print (\"Train Recall for category 1:\", recall1.eval({X: X_train, Y: Y_train}))\n",
    "        print (\"Test Recall for category 1:\", recall1.eval({X: X_test, Y: Y_test}))\n",
    "        print()\n",
    "        \n",
    "        # Calculating precision for category 0\n",
    "        predicted0_actual0 = tf.reduce_sum(tf.cast(tf.logical_and(tf.equal(tf.argmax(Z3), 0), tf.equal(tf.argmax(Y), 0)), \"float\"))\n",
    "        predicted0_actual1 = tf.reduce_sum(tf.cast(tf.logical_and(tf.equal(tf.argmax(Z3), 0), tf.equal(tf.argmax(Y), 1)), \"float\"))\n",
    "        predicted0_actual2 = tf.reduce_sum(tf.cast(tf.logical_and(tf.equal(tf.argmax(Z3), 0), tf.equal(tf.argmax(Y), 2)), \"float\")) \n",
    "        precission0=tf.divide(predicted0_actual0, tf.add_n([predicted0_actual0, predicted0_actual1, predicted0_actual2]))\n",
    "        print (\"Train Precission for category 0:\", precission0.eval({X: X_train, Y: Y_train}))\n",
    "        print (\"Test Precission for category 0:\", precission0.eval({X: X_test, Y: Y_test}))\n",
    "        print()\n",
    "        \n",
    "        # Calculating precision for category 1\n",
    "        predicted1_actual1 = tf.reduce_sum(tf.cast(tf.logical_and(tf.equal(tf.argmax(Z3), 1), tf.equal(tf.argmax(Y), 1)), \"float\"))\n",
    "        predicted1_actual0 = tf.reduce_sum(tf.cast(tf.logical_and(tf.equal(tf.argmax(Z3), 1), tf.equal(tf.argmax(Y), 0)), \"float\"))\n",
    "        predicted1_actual2 = tf.reduce_sum(tf.cast(tf.logical_and(tf.equal(tf.argmax(Z3), 1), tf.equal(tf.argmax(Y), 2)), \"float\")) \n",
    "        precission1=tf.divide(predicted1_actual1, tf.add_n([predicted1_actual1, predicted1_actual0, predicted1_actual2]))\n",
    "        print (\"Train Precission for category 1:\", precission1.eval({X: X_train, Y: Y_train}))\n",
    "        print (\"Test Precission for category 1:\", precission1.eval({X: X_test, Y: Y_test}))\n",
    "        print()\n",
    "        \n",
    "        return parameters\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 0: 1.202751\n",
      "Cost after epoch 100: 1.022156\n",
      "Cost after epoch 200: 0.939915\n",
      "Cost after epoch 300: 0.806697\n",
      "Cost after epoch 400: 0.674309\n",
      "Cost after epoch 500: 0.575392\n",
      "Cost after epoch 600: 0.497697\n",
      "Cost after epoch 700: 0.425454\n",
      "Cost after epoch 800: 0.398668\n",
      "Cost after epoch 900: 0.355663\n",
      "Cost after epoch 1000: 0.340438\n",
      "Cost after epoch 1100: 0.323813\n",
      "Cost after epoch 1200: 0.312160\n",
      "Cost after epoch 1300: 0.308741\n",
      "Cost after epoch 1400: 0.310111\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8254ee9fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters have been trained!\n",
      "\n",
      "Train Accuracy: 0.9032258\n",
      "Test Accuracy: 0.8490566\n",
      "\n",
      "Train Recall for category 0: 0.9851852\n",
      "Test Recall for category 0: 1.0\n",
      "\n",
      "Train Recall for category 1: 0.98913044\n",
      "Test Recall for category 1: 1.0\n",
      "\n",
      "Train Precission for category 0: 0.9172414\n",
      "Test Precission for category 0: 0.859375\n",
      "\n",
      "Train Precission for category 1: 0.88349515\n",
      "Test Precission for category 1: 0.8333333\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 28\n",
    "parameters = model(X_train, Y_train, X_test, Y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
